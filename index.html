<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras in autonomous driving">
  <meta name="keywords" content="Autonomous Driving, NeRF, multiple cameras">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras in autonomous driving</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/lego.png">
  <link rel="stylesheet" type="text/css" href="./static/css/test.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
  <script src="https://code.jquery.com/ui/1.12.1/jquery-ui.min.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://www.xxlong.site/Wonder3D/">
            Wonder3D
          </a>
          <a class="navbar-item" href="https://github.com/YvanYin/Metric3D">
            Metric3D
          </a>
          <a class="navbar-item" href="https://aim-uofa.github.io/FrozenRecon/">
            FrozenRecon
          </a>
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">UC-NeRF: Neural Radiance Field for Under-Calibrated Multi-view Cameras in Autonomous Driving</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.xxlong.site/">Kai Cheng*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.xxlong.site/">Xiaoxiao Long*</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://yvanyin.net/">Wei Yin</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.xxlong.site/">Jin Wang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.xxlong.site/">Zhiqiang Wu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://yuexinma.me/">Yuexin Ma</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://wang-kx.github.io/">Kaixuan Wang</a><sup>3</sup>
            </span>
            <span class="author-block">
              <a href="https://xiaozhichen.github.io/">Xiaozhi Chen</a><sup>3</sup>
            </span>
            <span class="author-block">
              <a href="http://staff.ustc.edu.cn/~xjchen99/">Xuejin Chen</a><sup>1</sup>
            </span>
           <p>(* Equal Contribution)</p>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China,</span>
            <span class="author-block"><sup>2</sup>PKU-Wuhan Institute for Artificial Intelligence,</span>
            <span class="author-block"><sup>3</sup>DJI Technology,</span>
            <span class="author-block"><sup>4</sup>ShanghaiTech University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="http://arxiv.org/abs/2311.16945"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/kcheng1021/UC-NeRF"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser"> -->

<!-- </section> -->

  <!-- <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div> -->
  <!-- <div class="image-container">
    <div class="image-overlay"></div>
    <img src="./static/images/zipdemo1.png" alt="Image 1" class="image image1">
    <img src="./static/images/ucdemo1.png" alt="Image 2" class="image image2">
  </div> -->
<!-- </section> -->


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->

<div id="outer-container">
  <div id="container">
    <img id="image1" src="./static/images/ucdemo1.png" />
    <div id="slider">
      <div class="arrow-right">&#9654;</div>
      <div class="arrow-left">&#9664;</div>
    </div>
    <img id="image2" src="./static/images/zipdemo1.png" />
  </div>
</div>
<script src="./static/js/test.js"></script>

<section class="section">
  <div class="container is-max-desktop">
    <div id="container1">
      <p>
        180&deg panorama images are rendered above. In under-calibrated multi-camera systems, the NeRF quality significantly degrades, along with color discrepancies, object ghosts, and wrong geometry. 
        Our UC-NeRF achieves high-quality rendering and accurate geometry in the challenging cases. <strong style="color: blue";> 
        （Slide the white line to compare the results between zipnerf and ours.）
        </strong>
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present UC-NeRF, a novel method tailored for novel view synthesis in under-calibrated multi-view camera systems of autonomous driving.
          </p>
          <p>
            Multi-camera setups find widespread use across various applications, such as autonomous driving, as they greatly expand sensing capabilities. 
            Despite the fast development of Neural radiance field (NeRF) techniques and their wide applications in both indoor and outdoor scenes, applying NeRF to multi-camera systems remains very challenging. This is primarily due to the inherent under-calibration issues in multi-camera setup, including inconsistent imaging effects stemming from separately calibrated image signal processing units in diverse cameras, and system errors arising from mechanical vibrations during driving that affect relative camera poses.
            In this paper, we present UC-NeRF, a novel method tailored for novel view synthesis in under-calibrated multi-view camera systems.
            Firstly, we propose a layer-based color correction to rectify the color inconsistency in different image regions. Second, we propose virtual warping to generate more viewpoint-diverse but color-consistent virtual views for color correction and 3D recovery. Finally, a spatiotemporally constrained pose refinement is designed for more robust and accurate pose calibration in multi-camera systems.
          </p>
          <p>
            Our method not only achieves state-of-the-art performance of novel view synthesis in multi-camera setups, but also effectively facilitates depth estimation in large-scale outdoor scenes with the synthesized novel views. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <video src="./static/videos/single_camera.mp4" autoplay controls muted loop playsinline></video>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">


    </div>

   <!--/ Re-rendering. -->
   <h3 class="title is-4">Rendering Comparison</h3>
   <p>
    <strong style="color: blue";> 
    Note that no depth supervision used in our UC-NeRF.
    </strong>
  </p>
   <section class="hero is-light is-small">
     <div class="hero-body">
       <div class="container">
          <div class="video-container">
            <video width="320" height="240" autoplay controls muted loop playsinline>
              <source src="./static/videos/398_uc.mp4" type="video/mp4">
            </video>
            <video width="320" height="240" autoplay controls muted loop playsinline>
              <source src="./static/videos/398_zip.mp4" type="video/mp4">
            </video>
          </div>
          <div class="video-container">
            <video width="320" height="240" autoplay controls muted loop playsinline>
              <source src="./static/videos/100_uc.mp4" type="video/mp4">
            </video>
            <video width="320" height="240" autoplay controls muted loop playsinline>
              <source src="./static/videos/100_zip.mp4" type="video/mp4">
            </video>
          </div>

          <br>
          <p style="font-size: 16px;">&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Our UC-NeRF(left)</b>&nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp &nbsp <b>Zip-NeRF(right).</b></p>
          <br>

          <p>More Comparison</p>
           <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
             <source src="./static/videos/more_compare.mp4"
                     type="video/mp4">
           </video>
       </div>
     </div>
   </section>
   <br>

    <!--/ Re-rendering. -->
  <h3 class="title is-4">Re-rendering in Novel Paranoma Views</h3>
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
          <!-- <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/1006final.mp4"
                    type="video/mp4">
          </video> -->

          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/113final.mp4"
                    type="video/mp4">
          </video>

          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/150final.mp4"
                    type="video/mp4">
          </video>

          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/1502_final.mp4"
                    type="video/mp4">
          </video>

          <!-- <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/34final.mp4"
                    type="video/mp4">
          </video> -->

          <!-- <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/1502_final.mp4"
                    type="video/mp4">
          </video> -->
      </div>
    </div>
  </section>
  <br>

    <!--/ Color correction -->
    <h3 class="title is-4">Comparison of Color Correction Strategy</h3>
    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/color_correction.mp4"
                      type="video/mp4">
            </video>
  
            <!-- <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/113final.mp4"
                      type="video/mp4">
            </video>
  
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/150final.mp4"
                      type="video/mp4">
            </video>
  
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/34final.mp4"
                      type="video/mp4">
            </video>
  
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/1502_final.mp4"
                      type="video/mp4">
            </video> -->
        </div>
      </div>
    </section>
    <br>

    <!--/ Virtual Warping -->
    <h3 class="title is-4">Solving the Overfitting of the Color Correction in the side views</h3>
    <section class="hero is-light is-small">
      <div class="hero-body">
        <div class="container">
            <video poster="" id="novw" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/148_novw.mp4"
                      type="video/mp4">
            </video>
        <p>
        Color correction of the side-view images might overfit, resulting in different areas not being under the same color space when rendering panoramic images. 
        For example, the color of the trees and flowers on both sides may not match reality. UC-NeRF can solve this problem.
        </p>
        <br>
            <video poster="" id="vw" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/148_vw.mp4"
                      type="video/mp4">
            </video>  
        </div>
      </div>
    </section>
    <br>

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Blurring caused by multi-camera pose errors</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4"></h3>
        <div class="content has-text-justified">
          <p>
              Errors from the relative transformation of different cameras can cause blurring. UC-NeRF can alleviate these artifacts. 
          </p>
        </div>

        <div class="title is-4">
            <img src="./static/images/blurring.png" style="display: block; margin-left: auto; margin-right: auto; width: 90%;"/>
        </div>
        <br/>
        <!--/ Interpolating. -->
      </div>
    </div>
    <!--/ Animation. -->

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-4">Application: Synthesized Views for Monocular Depth Estimation</h2>

        <!-- Interpolating. -->
        <h3 class="title is-4"></h3>
        <div class="content has-text-justified">
          <p>
            With the obtained 3D NeRF, we can generate additional photo-realistic images from novel viewpoints.
            The synthesized images can facilitate downstream perception tasks like monocular depth estimation. 
            We first train VA-DepthNet (ICLR2023), a state-of-the-art monocular depth estimation model, on the original real images.
            We then train the model by combining the original real images and the new synthesized images (VA-DepthNet*).
            As Tab.1 illustrates, the accuracy of the estimated depth is improved with such a data augmentation. 
            Fig.1 also shows such an operation leads to sharper edges and more accurate predictions.
            <strong style="color: blue";> It shows great potential of generating more training images for large perception model, such as <a href=https://github.com/YvanYin/Metric3D>Metric3D</a>.</strong>
          </p>
        </div>
        <div class="title is-4">
          <img src="./static/images/depthimprove.png"/>
        </div>
        <br/>
        <!--/ Interpolating. -->
      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{cheng2023ucnerf,
  title     = {UC-NeRF: Neural Radiance Field for Under-Calibrated multi-view cameras in autonomous driving},
  author    = {Kai Cheng and Xiaoxiao Long and Wei Yin and Jin Wang and Zhiqiang Wu and Yuexin Ma and Kaixuan Wang and Xiaozhi Chen and Xuejin Chen},
  year      = {2023},
  eprint={2311.16945},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}</code></pre>
    <!--<pre><code>@article{kchenguc23,
  author    = {Kai Cheng, Xiaoxiao Long, Wei Yin, Jin Wang, Zhiqiang Wu, Yuexin Ma, Kaixuan Wang, Xiaozhi Chen, Xuejin Chen},
  title     = {UC-NeRF},
  journal   = {arxiv},
  year      = {2023},
}</code></pre>-->
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
